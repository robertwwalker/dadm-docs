---
title: "Pivoting: Wide and Long"
author: "Robert W. Walker"
format: 
   html:
     code-fold: true
     theme: journal
     toc: true
     toc-depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

# Overarching Theme

In a 2014 paper in the __Journal of Statistical Software__, {citation: Wickham, H. (2014). Tidy Data. Journal of Statistical Software, 59(10), 1â€“23. [DOI](https://doi.org/10.18637/jss.v059.i10)} available from the [following link](https://www.jstatsoft.org/article/view/v059i10), Hadley Wickham provides the following succinct definition of **tidy data** -- data that accords with three key properties.

![tidy data](img/Screenshot 2023-02-01 at 4.43.55 PM.png)

The raison d'etre for pivoting operations examined in this post is the manipulation of *untidy* data into a tidy format.

# Package and Some Details

The tidyverse collection contains two types of two `pivot_` operations: `pivot_wider` and `pivot_longer` for transforming data from long to wide [`pivot_wider`] and wide to long [`pivot_longer`] formats in the `library(tidyr)`.  This quarto document will examine them and their use.

1. let us verify that they are a part of the `tidyverse`.  You will notice `tidyr` among the packages being attached.

```{r}
library(tidyverse)
```

2. They are accompanied by a **vignette**; a vignette is essentially an extended help file to detail the use of some R commands.  It can be accessed by making certain that the `tidyverse` [or just `tidyr`] is loaded [with either `library(tidyverse)` or `library(tidyr)`] and then

```
vignette("pivot")
```
![A view of the vignette obtained by vignette("pivot")](img/Screen Shot 2023-02-01 at 1.13.29 AM.png)

The data is contained in the packages so you can follow along and experiment with it, if you so choose.  Some of the examples overlap with the paper cited above.

I want to first use an example deploying familiar data: the dataset on Bond Funds.  Let's load it and I will use `datatable` from the `DT` package to display it.

```{r}
library(DT)
load(url("https://github.com/robertwwalker/DADMStuff/raw/master/Week-3-Data.RData"))
datatable(Bonds)
```

# A Tidy Table

Let me create a table to work with as a very small and manageable example to illustrate the concepts.  I will create a table of **Risk** and **Fees** and then turn it into an R `data.frame`.

```{r}
table(Bonds$Fees, Bonds$Risk) %>% data.frame()
```

This is **tidy** though the names are bad but that can be fixed.  Let me store this __long__ table as an object to manipulate and fix the names.  __Long__ and **tidy** are interchangeable in the way that I use the terms.  The correspond to 

```{r}
Bonds.Table.Long <- table(Bonds$Fees, Bonds$Risk) %>%
  data.frame() %>% 
  rename(Fees = Var1, Risk = Var2, Count = Freq)
Bonds.Table.Long
```

## Pivoting from Long to Wide

For display and because it is the most common way of seeing a table, I want to pivot it to wide form.  Basically, I want to create a 2 by 3 table with the values of Fees on the rows and the values of Risk on the Columns and each cell representing the number of Funds for that row-column pair.  *I should note it will actually be two-by-four because Fees is a margin of the table but the labels are treated as a variable.*  I will need to start with the `Bonds.Table.Long` above and create named columns from the categories of **Risk** with values drawn from the counts of the number of funds with that combination of characteristics.  The two key arguments in this case are where do the names come from `names_from` which is **Risk** and where do the values come from `values_from` which will be **Count**.

```{r}
Bonds.Table.Wide <- Bonds.Table.Long %>% 
  pivot_wider(names_from=Risk, values_from=Count)
Bonds.Table.Wide
```

Wide data has "data" in the column names and the tidyverse and tidy data analysis are built upon the idea that we have *units* and *variables*, this has information on the *units* in the column names.  Another way of putting it is that the values of **Risk** are spread across multiple columns of <u>values</u>.  A proper *unit* here would be a Fee-Risk pair [now that we have tabulated the data and left the raw data behind].

## Pivoting from Wide to Long

To <u>tidy</u> these data, I need to put that data back into a **row-centric** format.

Let me use `pivot_longer` for that.  Here, I need to tell R what variable the column names need to become (in quotes) and what variable the values need to become (also in quotes).  I want the names of variables currently called `Above Average, Average, Below Average` to become [or re-become] **Risk** and the values to become **Count** because they will measure how many bond funds in the original data represent that Fee-Risk pair.  **I should point out that spaces in column names are a nightmare.  I would have been far better off to fix them while they are values of the Risk variable before pivoting but I did not.  To address them, I will need tickmarks**  I will show three ways to do this.  

1. Negation because I want to pivot every column but **Fees**.  

2. I will enclose them in tickmarks.

3. I will fix the names using `janitor` and its `clean_names` function.  

::: {.panel-tabset}
## Negation 

First, let me do it by just telling R to use ! [not] Fees.

```{r}
BTL <- Bonds.Table.Wide %>% 
  pivot_longer(cols= -Fees, 
               names_to = "Risk", 
               values_to = "Count")
BTL
```

## Tickmarks

```{r}
BTL2 <- Bonds.Table.Wide %>% 
  pivot_longer(cols=c(`Above average`,Average,`Below average`), 
               names_to = "Risk", 
               values_to = "Count")
BTL2
```

## Cleaned Names

If we want to clean the names, a package introduced in class for tables using the pipe operator -- the `janitor` package and its `tabyl` function -- gives us a useful function called `clean_names`; it has a few arguments and is quite useful for transliteration from non-ASCII character sets, also.  The default is the "snake" case that will replace the spaces with underscores.  There are quite a few options for the argument, you can explore them by changing the argument among the options in quotations below.  Be careful about curly quotes and such, they are not valid ASCII characters and computer languages will complain.  The options are: 

`"snake", "small_camel", "big_camel", "screaming_snake", "parsed", "mixed", "lower_upper", "upper_lower", "swap", "all_caps", "lower_camel", "upper_camel", "internal_parsing", "none", "flip", "sentence", "random", "title"`

I intend to use the "mixed" type which maintains the capitalization but replaces spaces with `_` which is as close as I can get to the initial names with spaces while separating the lines.  Camel case would eliminate the spaces.

```{r, warning=FALSE, message=FALSE}
library(janitor)
Bonds.Table.Wide.Clean <- Bonds.Table.Wide %>%
  clean_names("mixed")
```

Now I have names that I don't need tickmarks for.  I want to make the columns `Above_average, Average,` and `Below_average` into the categories of the **Risk** variable with values going into **Count**.

```{r}
BTL3 <- Bonds.Table.Wide.Clean %>%
  pivot_longer(cols=c(Above_average,Average,Below_average), 
               names_to = "Risk", 
               values_to = "Count")
BTL3
```

:::

# A More Complicated Example From the Wild: Intel 10-k

I am going to use an Intel [INTC] Income Statement that I obtained from their website.  I chose the most recent one in Excel format which I have posted to my Github along with the income statement as .csv.

- [Download the Excel file](https://github.com/robertwwalker/DADMStuff/raw/master/Intel_Financial_Report-2022.xlsx)
- [Download the Single Income Statement Sheet Extracted and Saved as .csv](https://github.com/robertwwalker/DADMStuff/raw/master/Intel_Financial_Report-2022-IS.csv)
- [View the .csv on Github](https://github.com/robertwwalker/DADMStuff/blob/master/Intel_Financial_Report-2022-IS.csv)

I want to import the data from .csv.  If you follow the link above to view the Income Statement on Github you will see the extracted .csv file.

```{r}
Intel.IS <- read_csv("https://github.com/robertwwalker/DADMStuff/raw/master/Intel_Financial_Report-2022-IS.csv")
datatable(Intel.IS)
```

First, notice three identification lines that I will want to drop, lines 1, 3, and 21.  There are also some dollar signs and commas separating the amounts for formatting purposes that I need to fix; they currently prevent the data from being read as numeric.  For now, I will skip line 1 (`skip=1`) and force the columns to be character, numeric, numeric, numeric; `read_csv` abbreviates those with quoted "cnnn": `col_types="cnnn"`.  I also want to trim whitespaces with `trim_ws=T`  I learned this from the help.

```{r}
Intel.IS <- read_csv("https://github.com/robertwwalker/DADMStuff/raw/master/Intel_Financial_Report-2022-IS.csv", skip=1, col_types = "cnnn", trim_ws=T)
datatable(Intel.IS)
```

There are still warnings.  Data in the wild are messy but these are understandable.  The warnings tell me that I can run a command called `problems` from the `vroom` library to discover them.  

```{r}
library(vroom)
problems(Intel.IS)
```

Those are the original rows 3 and 21 that I wished to skip (recall I skipped 1).  I have one unnamed column and three columns that are named by the date of the Income Statement.  Let me rename the unnamed column to be Entry and then filter out the rows with **Entry** equal to "Income Statement [Abstract]" and "Weighted average shares of common stock outstanding:" as those are the identified issues.

```{r}
Intel.IS.Clean <- Intel.IS %>% 
  rename(Entry = ...1) %>%
  filter(!(Entry %in% c("Income Statement [Abstract]","Weighted average shares of common stock outstanding:")))
```

Let's view what we have now.

```{r}
datatable(Intel.IS.Clean)
```

That's good.  Now to pivot this.  After pivoting, I want to mutate the period variable to be a proper date format.  I also want to change the Entry to a factor variable so that the filter option in `datatable` will allow us to see just one accounting item by clicking on the available options -- Click in the box **All** at the top of the column **Entry** to see the scroll menu.  `datatable` has many neat features. 

```{r}
Intel.Tidy <- Intel.IS.Clean %>% pivot_longer(cols=c(`Dec. 31, 2022`,`Dec. 25, 2021`,`Dec. 26, 2020`), names_to = "period", values_to = "Quantity") %>% mutate(Entry = as.factor(Entry), date = as.Date(period, format="%b. %d,%Y"))
datatable(Intel.Tidy, filter = "top")
```

## Plot Some Financials

Finally, for this, let's plot Intel's **Net income**.  I will need to use the `scales` packages to get this into millions of dollars.

```{r, message=FALSE}
library(scales)
Intel.Tidy %>% filter(Entry %in% c("Net income","Operating income")) %>% 
  ggplot() + 
  aes(x=date, y=Quantity, color=Entry) + 
  geom_line() + 
  geom_point(size=3) +
  theme_minimal() + 
  scale_x_date() + 
  scale_y_continuous(labels = label_dollar(suffix=" Billion", scale=1e-3)) +
  labs(title="Intel Income from 10-k", x="Annual Report Date", color="Accounting Entry", y="") +
  scale_color_viridis_d()
```

# A Really Wide and Messy Example: Weather

The following weather.gov site contains [Portland's weather almanac](https://www.weather.gov/wrh/climate?wfo=pqr).  A link to a csv of all the data can be downloaded directly into R.  The datatable is huge because it covers four types of data -- high, low, precipitation, and snow, from October 1940 to the present.  It's also got some random characters in it that are undefined.

```{r}
NWS <- read.csv(url("https://www.weather.gov/source/pqr/climate/webdata/Portland_dailyclimatedata.csv"), skip=6, na.strings = c("M","-")) %>% 
  rename(Variable = X)
head(NWS, 10)
```

Days of the month are most of the variable names.  There is also a YR -- year, a MO -- month, and what variable -- TX is high temperature, TN is low temperature, PR is precipitation, and SN is snow.  To get this workable, I will need both a `pivot_longer` and a `pivot_wider`.  What I want is a date column, high, low, precipitation, and snow.

### Removing Junk

One thing that will prove troublesome is that `/A` appears in a few places. I want to remove it. I will ask R to find all of the character columns and remove `/A`.  I believe that this stands for trace accumulation. `where` is a helper to select columns with a set of characteristics and across allows me to transform those column-wise for all matching columns.

```{r}
NWS <- NWS %>% mutate(across(where(is.character), ~str_remove(.x, "/A")))
```

Now those are gone.  Now a few other cleaning steps.  I first create a daily dataset by removing the Averages/Totals which are the last column.  I also want to rename the columns to `Day.*` rather than `X*` for numbers 1 to 31.

```{r}
NWS.Daily <- NWS %>% select(-AVG.or.Total)
names(NWS.Daily) <- c("YR","MO","Variable",paste0("Day.",1:31))
```

Now I can pivot the to long form of the data by choosing to pivot all columns that start with **Day.**

```{r}
NWS.Daily <- NWS.Daily %>% 
  pivot_longer(., cols=starts_with("Day."), names_to = "Day", values_to = "value")
head(NWS.Daily)
```

Now to get rid of the Day. prefix to only keep the numbers and then pivot the four distinct variable back to columns.  I then want to recode some items, `T` is trace so I want to set it to 0.005 for both snow and precipitation before verifying that all the numeric columns are numeric and then combine the years, months, and days together into something that can be formatted as a date.

```{r}
NWS.Daily <- NWS.Daily %>% 
  mutate(Day = str_remove(Day, "Day.")) %>%  
  pivot_wider(., 
              names_from = "Variable", 
              values_from = "value") %>% 
  mutate(PR = recode(PR, T = "O.005"), 
         SN = recode(SN, T = "O.005")) %>% 
  mutate(TX = as.numeric(TX), 
         TN = as.numeric(TN), 
         PR = as.numeric(PR), 
         SN = as.numeric(SN), 
         date = as.Date(paste(MO,Day,YR,sep="-"), format="%m-%d-%Y")
         )
NWS.Daily %>% filter(is.na(date))
```

The output above shows me the first collection of rows where the **date** variable I created is missing.  Those are erroneous dates that are created because there is a cell for February 30 in the grid of original data.  I want to remove those and then to filter out rows with no valid values on any of the four quantitative variables.  This should give me clean data.

```{r}
NWS.Daily.Clean <- NWS.Daily %>% 
  filter(!(is.na(date))) %>% 
  filter(!(is.na(TX) & is.na(TN) & is.na(PR) & is.na(SN))) 
head(NWS.Daily.Clean)
```

## A Plot to Test the Data

Let me plot the data to verify the result.

```{r}
library(slider)
Plot.All <- NWS.Daily.Clean %>%
  mutate(Midpoint = (TX+TN)/2) %>%
  mutate(Mid.Temp = slide_dbl(Midpoint, mean, .before=6)) %>%
  ggplot() +
  aes(x=date) +
  geom_line(aes(y=Mid.Temp, alpha=0.001, color="red")) +
  scale_x_date() +
  geom_ribbon(aes(ymin=TN, ymax=TX), alpha=0.4, fill="red") +
  hrbrthemes::theme_ipsum_rc() + labs(title="Portland Temperatures", y="Degrees Fahrenheit", caption="The line is the 7 - Day Moving Average") + 
  guides(alpha="none", color="none")
Plot.Mini <- NWS.Daily.Clean %>%
  filter(date >= as.Date("2019-01-01")) %>%
  mutate(Midpoint = (TX+TN)/2) %>%
  mutate(Mid.Temp = slide_dbl(Midpoint, mean, .before=6)) %>%
  ggplot() +
  aes(x=date) +
  geom_line(aes(y=Mid.Temp, alpha=0.005, color="red")) +  scale_x_date() +
  geom_ribbon(aes(ymin=TN, ymax=TX), alpha=0.4, fill="red") +
  hrbrthemes::theme_ipsum_rc() + labs(title="Portland Temperatures", y="Degrees Fahrenheit", caption="The line is the 7 - Day Moving Average") + 
  guides(alpha="none", colour="none")
library(patchwork)
Plot.All / Plot.Mini
```

